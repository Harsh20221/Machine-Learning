
####* This File Contains the Whole Worflow from Start To finish in this we are loading and performing splitting and then performing embeddings and then storing the vector embeddings and atlast performing a similarity search to check if the vectors are stored efficently 
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS##? FAISS IS THE MODULE THAT HELPS US IN STORAGE OF THE VECTORS THAT ARE GENERATED BY THE HUGGINGFACE EMBEDDER 
from langchain_huggingface import HuggingFaceEmbeddings##? WE ARE USING LANGCHAIN-HUGGINGFACE EMBEDDINGS IN THIS PROJECT 
from langchain_text_splitters import RecursiveCharacterTextSplitter
##* Initializing the Hugging Face Embeddings Api
import os 
from dotenv import load_dotenv
load_dotenv()
os.environ['LANGCHAIN_API_KEY']=os.getenv("LANGCHAIN_API_KEY")
###*Actual process starts from here
loader=TextLoader('speech.txt')
documents=loader.load()
text_splitter=RecursiveCharacterTextSplitter(chunk_size=200,chunk_overlap=20)
docs=text_splitter.split_documents(documents)
embeddings=HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')
db=FAISS.from_documents(docs,embeddings)
#* Running a SIMILARITY SEARCH TO CHECK IF THE EMBEDDINGS ARE SUCCESSFULLY STORED IN THE DATABASE 
query="a people or with the desire"
""" result=db.similarity_search(query) """
""" print(result) """
###* We can Also convert the Vectorstore db into a Retreiver class , This allows us to easily use it in other langchain methods  which largely work with retreivers, It performs similar to the above similarity search but is easier and widely used 
retreiver=db.as_retriever()
result1=retreiver.invoke(query)
""" print(result1) """
###* We can also perform Similarity search with scores to determine the results and compare them to know  how closely they resembles the query 
result_and_score=db.similarity_search_with_score(query)
""" print(result_and_score) """
##* Store vector db in Local Machine
db.save_local('faiss_index')
##* Load the locally stored vector Db 
new_db=FAISS.load_local('faiss_index',embeddings,allow_dangerous_deserialization=True) ##? We are enabling the allow dangerous deserialization as the locally stored db is in pickle format which the FAISS considers as dangerous so we eneble it bacause we trust our db so that it can process our local 
newresult=new_db.similarity_search('The world must be made safe for democracy')
print(newresult)